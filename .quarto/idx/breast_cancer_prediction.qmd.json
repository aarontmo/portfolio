{"title":"Breast Cancer Classification","markdown":{"yaml":{"title":"Breast Cancer Classification"},"headingText":"Introduction","containsRefs":false,"markdown":"\n\n\n**Probelem:** Automate the diagnosis of breast cancer.\n\n**Background:** Breast cancer is one of the most prevalent forms of cancer among woment. Early detection and diagnosis (malignant or benign) is crucial for a positive response to treatment. \n\n**Goal:** The goal of the project is to train a machine learning model to predict whether breast tissue is malignant or benign. This classification will be based on several features that were extracted from microscopy images of fine needle aspirate of a breast tissue. \n\n**Data:** More information on the data can be found [here](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data/data) and [here](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)\n\n```{python}\n# import libraries\nimport os\nfrom pathlib import Path\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc, f1_score\n\nimport pickle\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n```\n\n```{python}\n# read in data\ndata_dir = Path(r\"C:\\Users\\aaron\\Desktop\\projects\\breast_cancer_prediction\\data\")\ndata = pd.read_csv(data_dir / 'breast_cancer.csv')\n```\n\n# Exploratory Data Analysis\n\nThe data include ten morphological and texture based features of cell nuclei in each image including the mean, standard error, and largest value (mean of three largest values) for each feature. The list below shows all the features that will be used for classification.\n\n- radius \n\n- texture (standard deviation of gray-scale values)\n\n- perimeter\n\n- area\n\n- smoothness\n\n- compactness\n\n- concavity\n\n- concave points\n\n- symmetry\n\n- fractal dimension\n\nWe can get a good idea of what features will be important in the classification model by looking at the distributions of each feature individually subsetted by the diagnosis. Because there are 30 feature columns we will only look at the mean of each the features above.\n\n```{python}\n# subset data for features ending in _mean and diagnosis\nmean_df = (\n    data\n    .filter(regex='mean|diagnosis')\n)\n\nmean_cols = [col for col in mean_df.columns if 'mean' in col]\n\nfor col in mean_cols:\n    plt.figure(figsize=(10,6))\n\n    sns.histplot(\n        mean_df,\n        x=col,\n        hue='diagnosis',\n        kde=True,\n        stat='density'\n    )\n    \n    plt.title(f'Distribution of {col}')\n    plt.show()\n```\n\nA few observations based on these plots:\n\n- It appears (with the a few exceptions) that the malignant group generally has a broader distribution comapared to the benign group which appears to have a tighter spread (more on this later).\n\n- With the exception of fractal dimension, symmetry, and smoothness there appears to be good separation between the malignant and benign distribtusions\n\n- The malignant group appears to have higher values on average compared to the benign group\n\nI am curious about the spread of the malignant and benign groups. Below is a table showing the standard deviations of the ten features.\n\n```{python}\n(\n    data\n    .filter(regex='mean|diagnosis')\n    .groupby('diagnosis')\n    .agg('std')\n)\n```\n\nFor most of the features the standard deviation of the malginant group is larger than benign group. The features where this is most apparent are the morphological features such as radius (3.20 vs 1.78) and perimeter (21.85 vs 11.81). It is generally known that cancer cells have irregular shapes and sizes some being larger and some being smaller than normal cells. This is a reasonable explanation for the wider spread of morphological features in the malignant group.\n\nOne of biggest concerns with classification tasks is how balanced the outcome variable is. The barchart below shows the total number of malignant and benign breat tissue samples.\n\n```{python}\n# diagnosis counts\nax = sns.countplot(\n    data,\n    x='diagnosis'\n)\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(\n        p.get_x() + p.get_width() / 2,\n        height + 3,\n        f'{height:.0f}',\n        ha=\"center\",\n    )\n\nplt.title('Outcome Count')\nplt.xlabel('Diagnosis')\nplt.show()\n\n```\n\n63% of the observations are benign. The outcome is slightly unbalanced but no to the point where we would need to use any imputation  or oversampling method.\n\n# Predictive Modeling\n\nThe following five machine learning algorithms will be trained and evaluated to verify which is the most accurate for this problem:\n\n- K-Nearest Neighbors (KNN)\n\n- Logistic Regression\n\n- Support Vector Classifier (SVC)\n\n- Decision Tree Classifier\n\n- Random Forest Classifier\n\n## Data Preprocessing\n\nThree preprocessing steps are necessary before training any machine learning algorithms: feature scaling, outcome binarization, and train test split. While feature scaling is necessary for some machine learning algorithms it is less imortant for others. Machine learning algorithms that rely on measuring distances between data points and boundaries require feature scaling to ensure each feature contributes equally to the classification. KNN, logistic regression, and support vector classifier require feature scaling while decision tree and random forest classifiers do not because they are non-parametric machine learning models.\n\n**Outcome Binarization**\n\nMost machine learning algorithms in the Scikit-Learn library assume the outcome to be binary so we will dichotomize the diagnosis as follows:\n\n- malignant = 1\n\n- benign = 0\n\n**Splitting Data**\n\nBefore splitting the data we want to check if there are any missing values in any of the columns\n\n```{python}\ndata.isnull().sum()\n```\n\nIt appears there are no missing values in any features except for the last column `Unnamed: 32` which are all empty. Next we will remove the empty column and the id column since it is not relevant to predicting diagnosis outcome.\n\n```{python}\nclean_data = (\n    data\n    .drop(columns=['id', 'Unnamed: 32'], axis=1)\n    .assign(diagnosis = np.where(data['diagnosis'] == 'M', 1, 0))\n)\n```\n\nWe will use a 70:30 training:test split which will result in 398 training samples and 171 testing samples. We will also stratify by diagnosis to ensure we the same proportions of malignant to benign samples in the training and testing set.\n\n```{python}\n# split into features and labels\nX = clean_data.drop(columns=['diagnosis'], axis=1)\ny = clean_data[['diagnosis']]\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=2024)\n\n# ensure class proportions was preserver between training and testing splits\nfig, ax = plt.subplots(1,2)\n\nsns.countplot(\n    y_train,\n    x='diagnosis',\n    ax=ax[0]\n    )\n\nax[0].set_title('Count of Training Labels')\n\nsns.countplot(\n    y_test,\n    x='diagnosis',\n    ax=ax[1]\n    )\n\nax[1].set_title('Count of Testing Labels')\n```\n\nThe plot above verifies that the proportion of positive and negative labels was preserved between the training and testing set.\n\nWe will perform the scaling before the training of the algorithms where it is required.\n\n## Model Training\n\n### K-Nearest Neighbors\n\nThe first model we will use is the K-Nearest neighbors model. This model works by assigning a label to a value based on its K nearest neighbors. The distance between points must be calculated using some distance measure. Below is an explanation of each hyperparameter. Because this model relys on distances between points we will scale the data before training.\n\n**Hyperparameters**\n\n- n_neighbors: The number of nearest neighbors to consider when making a prediction. Larger values lead to a more generalized prediction with the risk of underfitting the data. Small values lead to a model that is more sensitive to noise in the data potentially leading to overfitting.\n\n- weights: Determines how the distance between the point of interest and its nearest neighbors influence the prediction. Uniform weights consider all neighbors equally when getting a prediction. With distance weights closer neighbors have a larger impact on the prediction.\n\n- algorithm: The algorithm that is used to compute the neighbors: brute force, ball tree, KD tree, auto\n\n- leaf_size: Parameter passed to BallTree or KDTree algorithm, can effect the speed of the training\n\n- p: power parameter passed to the Minkowski metric. When p = 1 distance metric is city block, when p = 2 distance metric is euclidean. \n\nWe will be using a randomized search with a 5 fold cross validation to train the model and tune the hyperparameters.\n\n```{python}\n#| echo: true\n\nscaler = StandardScaler()\n\nx_train_scaled = scaler.fit_transform(x_train)\nx_test_scaled = scaler.transform(x_test)\n\ny_train = np.array(y_train).ravel()\ny_test = np.array(y_test).ravel()\n\nknn_param_dist = {\n    'n_neighbors': np.arange(1,31),\n    'weights': ['uniform', 'distance'],\n    'algorithm': ['ball_tree', 'kd_tree', 'brute', 'auto'],\n    'leaf_size': np.arange(10, 51, 5),\n    'p': [1,2]\n}\n\nknn = KNeighborsClassifier()\n\nknn_random_search = RandomizedSearchCV(\n    knn, \n    param_distributions=knn_param_dist,\n    n_iter=100,\n    cv=5,\n    n_jobs=1,\n    random_state=2024\n)\n\nknn_random_search.fit(x_train_scaled, y_train)\n```\n\nThe table below shows the hyperparameters that were chosen to produce the best result.\n\n```{python}\npd.DataFrame([knn_random_search.best_params_])\n```\n\nWe will be using the accuracy along with an ROC curve and AUC score to evaluate how well this model and future models perform. \n\n```{python}\nknn_preds = knn_random_search.predict(x_test_scaled)\nknn_probs = knn_random_search.predict_proba(x_test_scaled)[:, 1]\n\naccuracy = accuracy_score(y_test, knn_preds)\ncm = confusion_matrix(y_test, knn_preds)\n\nfpr, tpr, thresholds = roc_curve(y_test, knn_probs)\n\ntick_labels = data[['diagnosis']].drop_duplicates()\n\ndef resultsPlot(confusion_matrix, fpr, tpr):\n\n    roc_auc = auc(fpr, tpr)\n\n    fig, ax = plt.subplots(1,2, figsize=(9.5,5))\n    sns.heatmap(\n        confusion_matrix, \n        annot=True, \n        fmt='d', \n        cmap='Blues', \n        xticklabels=['B', 'M'], \n        yticklabels=['B', 'M'],\n        ax=ax[0])\n    ax[0].set_title('Confusion Matrix')\n    ax[0].set_xlabel('Predicted Label')\n    ax[0].set_ylabel('True Label')\n\n    ax[1].plot(\n        fpr,\n        tpr,\n        color='darkorange',\n        lw=2,\n        label=f'AUC = {roc_auc:.2f}'\n    )\n    ax[1].plot(\n        [0,1], \n        [0,1],\n        color='navy',\n        lw=2,\n        linestyle='--'\n    )\n    ax[1].set_xlabel('False Positive Rate')\n    ax[1].set_ylabel('True Positive Rate')\n    ax[1].set_title('ROC Curve')\n    ax[1].legend(loc='lower right')\n\nresultsPlot(cm, fpr, tpr)\n```\n\nThis model performed very well with an accuracy of 96.5% and AUC score of 0.997. As you can see from the confusion matrix there were 6 false negatives where the model incorrectly predicted a sample as benign when it was malignant.\n\n### Logistic Regression\n\nThe next model we will use is the logistic regression. Traditionally the logistic regression returns odds of a value being positive. However we can use the logistic regression as a classifier by converting the odds into probabilities and then setting a threshold to classify the samples into two categories. Because this project is primarily concerned with prediction I won't discuss the mathematical model and the effects of different beta coefficients. \n\n```{python}\nlr = LogisticRegression(fit_intercept=True)\n\nlr.fit(x_train_scaled, y_train)\n\nlr_probs = lr.predict_proba(x_test_scaled)[:,1]\nthreshs = np.arange(0.1,1,0.01)\n\naccs = []\nfor thresh in threshs:\n    preds = lr_probs > thresh\n    acc = accuracy_score(y_test, preds)\n    accs.append(acc)\n\nacc_df = pd.DataFrame(\n    {\n        'threshs': threshs,\n        'accs': accs})\n\nplt.plot(threshs, accs)\nplt.xlabel('Thresholds')\nplt.ylabel('Accuracy')\n```\n\nAccording to the plot above the accuracy reaches a maximum at a threshold around 0.5, so we will us that as our cutoff. \n\n```{python}\nlr_preds = lr_probs > 0.5\n\nfpr, tpr, threshold = roc_curve(y_test, lr_probs)\n\nlr_cm = confusion_matrix(y_test, lr_preds)\n\nresultsPlot(lr_cm, fpr, tpr)\n\n```\n\nThe logistic regression also did a very good job with this classification task with an accuracy score of 97.7% and an AUC of 0.995. Similarly to the KNN model the logistic regression misclassified 4 malignant samples as benign.\n\n### Decision Tree\n\nThe next model we will evaluate is a simple decision tree. The decision tree model works by using the features to split the samples into different buckets for classification. Due to the way a decision tree works feature scaling is not necessary for this model. The decision tree has the following hyperparameters that need to be tuned.\n\n- criterion: the function to measure the quality of the split at each node, options are gini impurity, log loss, and entropy\n\n- splitter: how the algorithm determines the split at each node, options are best and random\n\n- maximum depth: controls how deep the tree can get. The deeper the tree the higher likelihood of overfitting, the shallower the tree the higher the likelihood of underfitting.\n\n- minimum samples splt: the minimum number of samples needed before an internal leaf node splits\n\n- minimum samples leaf: the minimum number of samples required for a node to be a leaf node\n\n- max features: the number of samples that are considered for each leaf node. We will be using either log2(number of features) or sqrt(number of features).\n\nSimilar to the KNN model we will be using a randomized cross validation search for training and tuning the decision tree model.\n\n```{python}\ndt_tune_dist = {\n    'criterion': ['gini', 'entropy', 'log_loss'],\n    'splitter': ['best', 'random'],\n    'max_depth': np.arange(1,21,1),\n    'min_samples_split': np.arange(2,21,1),\n    'min_samples_leaf': np.arange(1,21,1),\n    'max_features': ['log2', 'sqrt']\n}\n\ndt = DecisionTreeClassifier()\n\ndt_random_search = RandomizedSearchCV(\n    dt,\n    param_distributions=dt_tune_dist,\n    n_iter=100,\n    cv=5,\n    n_jobs=1,\n    random_state=2024\n)\n\ndt_random_search.fit(x_train, y_train)\n\n```\n\n```{python}\n\ndt_best_model = dt_random_search.best_estimator_\ndt_feature_imp = dt_best_model.feature_importances_\n\ndt_feature_imp_df = pd.DataFrame({\n    'feature': x_train.columns,\n    'importance': dt_feature_imp\n}).sort_values('importance', ascending=False)\n\nsns.barplot(\n    dt_feature_imp_df,\n    y='feature',\n    x='importance'\n)   \n\nplt.title('Decision Tree Feature Importance')\n\n```\n\n```{python}\ndt_preds = dt_random_search.predict(x_test)\ndt_probs = dt_random_search.predict_proba(x_test)[:, 1]\n\ndt_cm = confusion_matrix(y_test, dt_preds)\n\ndt_fpr, dt_tpr, thresholds = roc_curve(y_test, dt_probs)\n\nresultsPlot(dt_cm, dt_fpr, dt_tpr)\n\n```\n\n### Random Forest\n\n```{python}\n\n# rf_para_dist = {\n#     'n_estimators': np.arange(1,500,1),\n#     'criterion': ['gini', 'entropy', 'log_loss'],\n#     'max_depth': np.arange(1,21,1),\n#     'min_samples_split': np.arange(2,21,1),\n#     'min_samples_leaf': np.arange(1,21,1),\n#     'max_features': ['log2', 'sqrt']\n# }\n\n# rf = RandomForestClassifier()\n\n# rf_random_search = RandomizedSearchCV(\n#     rf,\n#     param_distributions=rf_para_dist,\n#     n_iter=100,\n#     cv=5,\n#     n_jobs=1,\n#     random_state=2024\n# )\n\n# rf_random_search.fit(x_train, y_train)\n\n```\n\n```{python}\n# ml_model_dir = Path(r\"C:\\Users\\aaron\\Desktop\\projects\\breast_cancer_prediction\\ml_models\")\n# rf_pickle_path = ml_model_dir / 'breast_cancer_rf_model.pkl'\n# with open(rf_pickle_path, 'wb') as file:\n#     pickle.dump(rf_random_search, file)\n```\n\n```{python}\nml_models_dir = Path(r\"C:\\Users\\aaron\\Desktop\\projects\\breast_cancer_prediction\\ml_models\")\nwith open(ml_models_dir / 'breast_cancer_rf_model.pkl', 'rb') as file:\n    rf_random_search = pickle.load(file)\n\nrf_best_model = rf_random_search.best_estimator_\nrf_feature_imp = rf_best_model.feature_importances_\nrf_feature_imp_df = pd.DataFrame({\n    'feature': x_train.columns,\n    'importance': rf_feature_imp\n}).sort_values('importance', ascending=False)\n\nsns.barplot(\n    rf_feature_imp_df,\n    y='feature',\n    x='importance'\n)\nplt.title('Random Forest Feature Importance')\n\n```\n\n```{python}\n\nrf_preds = rf_random_search.predict(x_test)\nrf_cm = confusion_matrix(y_test, rf_preds)\nrf_probs = rf_random_search.predict_proba(x_train)[:, 1]\nrf_fpr, rf_tpr, thresholds = roc_curve(y_test, rf_preds)\n\n\nresultsPlot(rf_cm, rf_fpr, rf_tpr)\n```\n\n## Comparing Models","srcMarkdownNoYaml":"\n\n# Introduction\n\n**Probelem:** Automate the diagnosis of breast cancer.\n\n**Background:** Breast cancer is one of the most prevalent forms of cancer among woment. Early detection and diagnosis (malignant or benign) is crucial for a positive response to treatment. \n\n**Goal:** The goal of the project is to train a machine learning model to predict whether breast tissue is malignant or benign. This classification will be based on several features that were extracted from microscopy images of fine needle aspirate of a breast tissue. \n\n**Data:** More information on the data can be found [here](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data/data) and [here](https://archive.ics.uci.edu/dataset/17/breast+cancer+wisconsin+diagnostic)\n\n```{python}\n# import libraries\nimport os\nfrom pathlib import Path\n\nimport pandas as pd\nimport numpy as np\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc, f1_score\n\nimport pickle\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\n\n```\n\n```{python}\n# read in data\ndata_dir = Path(r\"C:\\Users\\aaron\\Desktop\\projects\\breast_cancer_prediction\\data\")\ndata = pd.read_csv(data_dir / 'breast_cancer.csv')\n```\n\n# Exploratory Data Analysis\n\nThe data include ten morphological and texture based features of cell nuclei in each image including the mean, standard error, and largest value (mean of three largest values) for each feature. The list below shows all the features that will be used for classification.\n\n- radius \n\n- texture (standard deviation of gray-scale values)\n\n- perimeter\n\n- area\n\n- smoothness\n\n- compactness\n\n- concavity\n\n- concave points\n\n- symmetry\n\n- fractal dimension\n\nWe can get a good idea of what features will be important in the classification model by looking at the distributions of each feature individually subsetted by the diagnosis. Because there are 30 feature columns we will only look at the mean of each the features above.\n\n```{python}\n# subset data for features ending in _mean and diagnosis\nmean_df = (\n    data\n    .filter(regex='mean|diagnosis')\n)\n\nmean_cols = [col for col in mean_df.columns if 'mean' in col]\n\nfor col in mean_cols:\n    plt.figure(figsize=(10,6))\n\n    sns.histplot(\n        mean_df,\n        x=col,\n        hue='diagnosis',\n        kde=True,\n        stat='density'\n    )\n    \n    plt.title(f'Distribution of {col}')\n    plt.show()\n```\n\nA few observations based on these plots:\n\n- It appears (with the a few exceptions) that the malignant group generally has a broader distribution comapared to the benign group which appears to have a tighter spread (more on this later).\n\n- With the exception of fractal dimension, symmetry, and smoothness there appears to be good separation between the malignant and benign distribtusions\n\n- The malignant group appears to have higher values on average compared to the benign group\n\nI am curious about the spread of the malignant and benign groups. Below is a table showing the standard deviations of the ten features.\n\n```{python}\n(\n    data\n    .filter(regex='mean|diagnosis')\n    .groupby('diagnosis')\n    .agg('std')\n)\n```\n\nFor most of the features the standard deviation of the malginant group is larger than benign group. The features where this is most apparent are the morphological features such as radius (3.20 vs 1.78) and perimeter (21.85 vs 11.81). It is generally known that cancer cells have irregular shapes and sizes some being larger and some being smaller than normal cells. This is a reasonable explanation for the wider spread of morphological features in the malignant group.\n\nOne of biggest concerns with classification tasks is how balanced the outcome variable is. The barchart below shows the total number of malignant and benign breat tissue samples.\n\n```{python}\n# diagnosis counts\nax = sns.countplot(\n    data,\n    x='diagnosis'\n)\n\nfor p in ax.patches:\n    height = p.get_height()\n    ax.text(\n        p.get_x() + p.get_width() / 2,\n        height + 3,\n        f'{height:.0f}',\n        ha=\"center\",\n    )\n\nplt.title('Outcome Count')\nplt.xlabel('Diagnosis')\nplt.show()\n\n```\n\n63% of the observations are benign. The outcome is slightly unbalanced but no to the point where we would need to use any imputation  or oversampling method.\n\n# Predictive Modeling\n\nThe following five machine learning algorithms will be trained and evaluated to verify which is the most accurate for this problem:\n\n- K-Nearest Neighbors (KNN)\n\n- Logistic Regression\n\n- Support Vector Classifier (SVC)\n\n- Decision Tree Classifier\n\n- Random Forest Classifier\n\n## Data Preprocessing\n\nThree preprocessing steps are necessary before training any machine learning algorithms: feature scaling, outcome binarization, and train test split. While feature scaling is necessary for some machine learning algorithms it is less imortant for others. Machine learning algorithms that rely on measuring distances between data points and boundaries require feature scaling to ensure each feature contributes equally to the classification. KNN, logistic regression, and support vector classifier require feature scaling while decision tree and random forest classifiers do not because they are non-parametric machine learning models.\n\n**Outcome Binarization**\n\nMost machine learning algorithms in the Scikit-Learn library assume the outcome to be binary so we will dichotomize the diagnosis as follows:\n\n- malignant = 1\n\n- benign = 0\n\n**Splitting Data**\n\nBefore splitting the data we want to check if there are any missing values in any of the columns\n\n```{python}\ndata.isnull().sum()\n```\n\nIt appears there are no missing values in any features except for the last column `Unnamed: 32` which are all empty. Next we will remove the empty column and the id column since it is not relevant to predicting diagnosis outcome.\n\n```{python}\nclean_data = (\n    data\n    .drop(columns=['id', 'Unnamed: 32'], axis=1)\n    .assign(diagnosis = np.where(data['diagnosis'] == 'M', 1, 0))\n)\n```\n\nWe will use a 70:30 training:test split which will result in 398 training samples and 171 testing samples. We will also stratify by diagnosis to ensure we the same proportions of malignant to benign samples in the training and testing set.\n\n```{python}\n# split into features and labels\nX = clean_data.drop(columns=['diagnosis'], axis=1)\ny = clean_data[['diagnosis']]\n\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=2024)\n\n# ensure class proportions was preserver between training and testing splits\nfig, ax = plt.subplots(1,2)\n\nsns.countplot(\n    y_train,\n    x='diagnosis',\n    ax=ax[0]\n    )\n\nax[0].set_title('Count of Training Labels')\n\nsns.countplot(\n    y_test,\n    x='diagnosis',\n    ax=ax[1]\n    )\n\nax[1].set_title('Count of Testing Labels')\n```\n\nThe plot above verifies that the proportion of positive and negative labels was preserved between the training and testing set.\n\nWe will perform the scaling before the training of the algorithms where it is required.\n\n## Model Training\n\n### K-Nearest Neighbors\n\nThe first model we will use is the K-Nearest neighbors model. This model works by assigning a label to a value based on its K nearest neighbors. The distance between points must be calculated using some distance measure. Below is an explanation of each hyperparameter. Because this model relys on distances between points we will scale the data before training.\n\n**Hyperparameters**\n\n- n_neighbors: The number of nearest neighbors to consider when making a prediction. Larger values lead to a more generalized prediction with the risk of underfitting the data. Small values lead to a model that is more sensitive to noise in the data potentially leading to overfitting.\n\n- weights: Determines how the distance between the point of interest and its nearest neighbors influence the prediction. Uniform weights consider all neighbors equally when getting a prediction. With distance weights closer neighbors have a larger impact on the prediction.\n\n- algorithm: The algorithm that is used to compute the neighbors: brute force, ball tree, KD tree, auto\n\n- leaf_size: Parameter passed to BallTree or KDTree algorithm, can effect the speed of the training\n\n- p: power parameter passed to the Minkowski metric. When p = 1 distance metric is city block, when p = 2 distance metric is euclidean. \n\nWe will be using a randomized search with a 5 fold cross validation to train the model and tune the hyperparameters.\n\n```{python}\n#| echo: true\n\nscaler = StandardScaler()\n\nx_train_scaled = scaler.fit_transform(x_train)\nx_test_scaled = scaler.transform(x_test)\n\ny_train = np.array(y_train).ravel()\ny_test = np.array(y_test).ravel()\n\nknn_param_dist = {\n    'n_neighbors': np.arange(1,31),\n    'weights': ['uniform', 'distance'],\n    'algorithm': ['ball_tree', 'kd_tree', 'brute', 'auto'],\n    'leaf_size': np.arange(10, 51, 5),\n    'p': [1,2]\n}\n\nknn = KNeighborsClassifier()\n\nknn_random_search = RandomizedSearchCV(\n    knn, \n    param_distributions=knn_param_dist,\n    n_iter=100,\n    cv=5,\n    n_jobs=1,\n    random_state=2024\n)\n\nknn_random_search.fit(x_train_scaled, y_train)\n```\n\nThe table below shows the hyperparameters that were chosen to produce the best result.\n\n```{python}\npd.DataFrame([knn_random_search.best_params_])\n```\n\nWe will be using the accuracy along with an ROC curve and AUC score to evaluate how well this model and future models perform. \n\n```{python}\nknn_preds = knn_random_search.predict(x_test_scaled)\nknn_probs = knn_random_search.predict_proba(x_test_scaled)[:, 1]\n\naccuracy = accuracy_score(y_test, knn_preds)\ncm = confusion_matrix(y_test, knn_preds)\n\nfpr, tpr, thresholds = roc_curve(y_test, knn_probs)\n\ntick_labels = data[['diagnosis']].drop_duplicates()\n\ndef resultsPlot(confusion_matrix, fpr, tpr):\n\n    roc_auc = auc(fpr, tpr)\n\n    fig, ax = plt.subplots(1,2, figsize=(9.5,5))\n    sns.heatmap(\n        confusion_matrix, \n        annot=True, \n        fmt='d', \n        cmap='Blues', \n        xticklabels=['B', 'M'], \n        yticklabels=['B', 'M'],\n        ax=ax[0])\n    ax[0].set_title('Confusion Matrix')\n    ax[0].set_xlabel('Predicted Label')\n    ax[0].set_ylabel('True Label')\n\n    ax[1].plot(\n        fpr,\n        tpr,\n        color='darkorange',\n        lw=2,\n        label=f'AUC = {roc_auc:.2f}'\n    )\n    ax[1].plot(\n        [0,1], \n        [0,1],\n        color='navy',\n        lw=2,\n        linestyle='--'\n    )\n    ax[1].set_xlabel('False Positive Rate')\n    ax[1].set_ylabel('True Positive Rate')\n    ax[1].set_title('ROC Curve')\n    ax[1].legend(loc='lower right')\n\nresultsPlot(cm, fpr, tpr)\n```\n\nThis model performed very well with an accuracy of 96.5% and AUC score of 0.997. As you can see from the confusion matrix there were 6 false negatives where the model incorrectly predicted a sample as benign when it was malignant.\n\n### Logistic Regression\n\nThe next model we will use is the logistic regression. Traditionally the logistic regression returns odds of a value being positive. However we can use the logistic regression as a classifier by converting the odds into probabilities and then setting a threshold to classify the samples into two categories. Because this project is primarily concerned with prediction I won't discuss the mathematical model and the effects of different beta coefficients. \n\n```{python}\nlr = LogisticRegression(fit_intercept=True)\n\nlr.fit(x_train_scaled, y_train)\n\nlr_probs = lr.predict_proba(x_test_scaled)[:,1]\nthreshs = np.arange(0.1,1,0.01)\n\naccs = []\nfor thresh in threshs:\n    preds = lr_probs > thresh\n    acc = accuracy_score(y_test, preds)\n    accs.append(acc)\n\nacc_df = pd.DataFrame(\n    {\n        'threshs': threshs,\n        'accs': accs})\n\nplt.plot(threshs, accs)\nplt.xlabel('Thresholds')\nplt.ylabel('Accuracy')\n```\n\nAccording to the plot above the accuracy reaches a maximum at a threshold around 0.5, so we will us that as our cutoff. \n\n```{python}\nlr_preds = lr_probs > 0.5\n\nfpr, tpr, threshold = roc_curve(y_test, lr_probs)\n\nlr_cm = confusion_matrix(y_test, lr_preds)\n\nresultsPlot(lr_cm, fpr, tpr)\n\n```\n\nThe logistic regression also did a very good job with this classification task with an accuracy score of 97.7% and an AUC of 0.995. Similarly to the KNN model the logistic regression misclassified 4 malignant samples as benign.\n\n### Decision Tree\n\nThe next model we will evaluate is a simple decision tree. The decision tree model works by using the features to split the samples into different buckets for classification. Due to the way a decision tree works feature scaling is not necessary for this model. The decision tree has the following hyperparameters that need to be tuned.\n\n- criterion: the function to measure the quality of the split at each node, options are gini impurity, log loss, and entropy\n\n- splitter: how the algorithm determines the split at each node, options are best and random\n\n- maximum depth: controls how deep the tree can get. The deeper the tree the higher likelihood of overfitting, the shallower the tree the higher the likelihood of underfitting.\n\n- minimum samples splt: the minimum number of samples needed before an internal leaf node splits\n\n- minimum samples leaf: the minimum number of samples required for a node to be a leaf node\n\n- max features: the number of samples that are considered for each leaf node. We will be using either log2(number of features) or sqrt(number of features).\n\nSimilar to the KNN model we will be using a randomized cross validation search for training and tuning the decision tree model.\n\n```{python}\ndt_tune_dist = {\n    'criterion': ['gini', 'entropy', 'log_loss'],\n    'splitter': ['best', 'random'],\n    'max_depth': np.arange(1,21,1),\n    'min_samples_split': np.arange(2,21,1),\n    'min_samples_leaf': np.arange(1,21,1),\n    'max_features': ['log2', 'sqrt']\n}\n\ndt = DecisionTreeClassifier()\n\ndt_random_search = RandomizedSearchCV(\n    dt,\n    param_distributions=dt_tune_dist,\n    n_iter=100,\n    cv=5,\n    n_jobs=1,\n    random_state=2024\n)\n\ndt_random_search.fit(x_train, y_train)\n\n```\n\n```{python}\n\ndt_best_model = dt_random_search.best_estimator_\ndt_feature_imp = dt_best_model.feature_importances_\n\ndt_feature_imp_df = pd.DataFrame({\n    'feature': x_train.columns,\n    'importance': dt_feature_imp\n}).sort_values('importance', ascending=False)\n\nsns.barplot(\n    dt_feature_imp_df,\n    y='feature',\n    x='importance'\n)   \n\nplt.title('Decision Tree Feature Importance')\n\n```\n\n```{python}\ndt_preds = dt_random_search.predict(x_test)\ndt_probs = dt_random_search.predict_proba(x_test)[:, 1]\n\ndt_cm = confusion_matrix(y_test, dt_preds)\n\ndt_fpr, dt_tpr, thresholds = roc_curve(y_test, dt_probs)\n\nresultsPlot(dt_cm, dt_fpr, dt_tpr)\n\n```\n\n### Random Forest\n\n```{python}\n\n# rf_para_dist = {\n#     'n_estimators': np.arange(1,500,1),\n#     'criterion': ['gini', 'entropy', 'log_loss'],\n#     'max_depth': np.arange(1,21,1),\n#     'min_samples_split': np.arange(2,21,1),\n#     'min_samples_leaf': np.arange(1,21,1),\n#     'max_features': ['log2', 'sqrt']\n# }\n\n# rf = RandomForestClassifier()\n\n# rf_random_search = RandomizedSearchCV(\n#     rf,\n#     param_distributions=rf_para_dist,\n#     n_iter=100,\n#     cv=5,\n#     n_jobs=1,\n#     random_state=2024\n# )\n\n# rf_random_search.fit(x_train, y_train)\n\n```\n\n```{python}\n# ml_model_dir = Path(r\"C:\\Users\\aaron\\Desktop\\projects\\breast_cancer_prediction\\ml_models\")\n# rf_pickle_path = ml_model_dir / 'breast_cancer_rf_model.pkl'\n# with open(rf_pickle_path, 'wb') as file:\n#     pickle.dump(rf_random_search, file)\n```\n\n```{python}\nml_models_dir = Path(r\"C:\\Users\\aaron\\Desktop\\projects\\breast_cancer_prediction\\ml_models\")\nwith open(ml_models_dir / 'breast_cancer_rf_model.pkl', 'rb') as file:\n    rf_random_search = pickle.load(file)\n\nrf_best_model = rf_random_search.best_estimator_\nrf_feature_imp = rf_best_model.feature_importances_\nrf_feature_imp_df = pd.DataFrame({\n    'feature': x_train.columns,\n    'importance': rf_feature_imp\n}).sort_values('importance', ascending=False)\n\nsns.barplot(\n    rf_feature_imp_df,\n    y='feature',\n    x='importance'\n)\nplt.title('Random Forest Feature Importance')\n\n```\n\n```{python}\n\nrf_preds = rf_random_search.predict(x_test)\nrf_cm = confusion_matrix(y_test, rf_preds)\nrf_probs = rf_random_search.predict_proba(x_train)[:, 1]\nrf_fpr, rf_tpr, thresholds = roc_curve(y_test, rf_preds)\n\n\nresultsPlot(rf_cm, rf_fpr, rf_tpr)\n```\n\n## Comparing Models"},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"jupyter"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":true,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["styles.css"],"toc":true,"output-file":"breast_cancer_prediction.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.5.56","theme":"sandstone","author":"Aaron Morris","title":"Breast Cancer Classification"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}